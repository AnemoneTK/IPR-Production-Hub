name: Backup Supabase to R2

on:
  schedule:
    - cron: "0 3 * * *"
  workflow_dispatch:

jobs:
  backup_and_upload:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      # ðŸ”¥ à¹à¸à¹‰à¹„à¸‚à¸ªà¹ˆà¸§à¸™à¸™à¸µà¹‰: à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ Client à¹€à¸§à¸­à¸£à¹Œà¸Šà¸±à¸™ 17
      - name: Install PostgreSQL Client 17
        run: |
          sudo apt-get install -y wget gnupg2 lsb-release
          wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
          echo "deb http://apt.postgresql.org/pub/repos/apt/ $(lsb_release -cs)-pgdg main" | sudo tee /etc/apt/sources.list.d/pgdg.list
          sudo apt-get update
          sudo apt-get install -y postgresql-client-17

      - name: Dump Database
        run: |
          FILENAME="backup-$(date +'%Y-%m-%d-%H%M').sql"

          # à¹ƒà¸Šà¹‰ URL à¸ˆà¸²à¸ Secret (Connection Pooler)
          # à¹€à¸žà¸´à¹ˆà¸¡ flag --no-owner --no-acl à¹€à¸žà¸·à¹ˆà¸­à¸¥à¸”à¸›à¸±à¸à¸«à¸²à¸ªà¸´à¸—à¸˜à¸´à¹Œà¸•à¸­à¸™ Restore
          pg_dump "${{ secrets.SUPABASE_DB_URL }}" -f "$FILENAME" --no-owner --no-acl

          ls -lh "$FILENAME"
          echo "BACKUP_FILENAME=$FILENAME" >> $GITHUB_ENV

      - name: Configure AWS CLI for Cloudflare R2
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.R2_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          aws-region: auto

      - name: Upload to R2
        run: |
          aws s3 cp ${{ env.BACKUP_FILENAME }} s3://${{ secrets.R2_BUCKET_NAME }}/database-backups/${{ env.BACKUP_FILENAME }} \
            --endpoint-url https://${{ secrets.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com

      - name: Cleanup
        if: always()
        run: |
          if [ -n "${{ env.BACKUP_FILENAME }}" ]; then
            rm -f ${{ env.BACKUP_FILENAME }}
          fi
