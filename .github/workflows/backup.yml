name: Backup Supabase to R2

on:
  schedule:
    - cron: "0 3 * * *"
  workflow_dispatch:

jobs:
  backup_and_upload:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install PostgreSQL Client 17
        run: |
          sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list'
          wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
          sudo apt-get update
          sudo apt-get install -y postgresql-client-17

      # 2. à¸ªà¸±à¹ˆà¸‡ Dump à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ (à¹‚à¸”à¸¢à¸£à¸°à¸šà¸¸ Path à¸‚à¸­à¸‡à¹€à¸§à¸­à¸£à¹Œà¸Šà¸±à¸™ 17 à¹à¸šà¸šà¹€à¸ˆà¸²à¸°à¸ˆà¸‡)
      - name: Dump Database
        run: |
          FILENAME="backup-$(date +'%Y-%m-%d-%H%M').sql"

          # ðŸ”¥ à¹ƒà¸Šà¹‰ /usr/lib/postgresql/17/bin/pg_dump à¹€à¸žà¸·à¹ˆà¸­à¹€à¸£à¸µà¸¢à¸à¸•à¸±à¸§ v17 à¹‚à¸”à¸¢à¸•à¸£à¸‡
          /usr/lib/postgresql/17/bin/pg_dump "${{ secrets.SUPABASE_DB_URL }}" -f "$FILENAME" --no-owner --no-acl

          ls -lh "$FILENAME"
          echo "BACKUP_FILENAME=$FILENAME" >> $GITHUB_ENV

      - name: Configure AWS CLI for Cloudflare R2
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.R2_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          aws-region: auto

      - name: Upload to R2
        run: |
          aws s3 cp ${{ env.BACKUP_FILENAME }} s3://${{ secrets.R2_BUCKET_NAME }}/database-backups/${{ env.BACKUP_FILENAME }} \
            --endpoint-url https://${{ secrets.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com

      - name: Cleanup
        if: always()
        run: |
          if [ -n "${{ env.BACKUP_FILENAME }}" ]; then
            rm -f ${{ env.BACKUP_FILENAME }}
          fi
